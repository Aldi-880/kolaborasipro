{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAMA : MT ALDI SYAHPRANATA\n",
    "NIM  : 200411100175\n",
    "NAMA : FATHONI SYAENULLAH\n",
    "NIM  : 200411100073\n",
    "\n",
    "GitHub : Aldi-880 - https://github.com/Aldi-880/kolaborasipro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ubuntu/.local/lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/.local/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in /home/ubuntu/.local/lib/python3.8/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/ubuntu/.local/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.8/site-packages (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install openpyxl\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>4060.0</td>\n",
       "      <td>4080.0</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>4060.0</td>\n",
       "      <td>3896.035889</td>\n",
       "      <td>94848800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-16</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>3876.843506</td>\n",
       "      <td>96042200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>3980.0</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>3953.612793</td>\n",
       "      <td>169375800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>4050.0</td>\n",
       "      <td>4060.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>3876.843506</td>\n",
       "      <td>82101200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>4060.0</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>4110.0</td>\n",
       "      <td>3944.016602</td>\n",
       "      <td>77489000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2023-06-09</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4140.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>3982.401123</td>\n",
       "      <td>83014700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>4050.0</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>4050.0</td>\n",
       "      <td>4050.000000</td>\n",
       "      <td>94687300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>4060.0</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>4030.000000</td>\n",
       "      <td>69609000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2023-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>3990.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>3990.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>12540000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Open    High     Low   Close    Adj Close       Volume\n",
       "0    2022-06-15  4060.0  4080.0  4030.0  4060.0  3896.035889   94848800.0\n",
       "1    2022-06-16  4120.0  4120.0  4030.0  4040.0  3876.843506   96042200.0\n",
       "2    2022-06-17  4010.0  4120.0  3980.0  4120.0  3953.612793  169375800.0\n",
       "3    2022-06-20  4050.0  4060.0  4000.0  4040.0  3876.843506   82101200.0\n",
       "4    2022-06-21  4060.0  4120.0  4030.0  4110.0  3944.016602   77489000.0\n",
       "..          ...     ...     ...     ...     ...          ...          ...\n",
       "243  2023-06-09  4170.0  4170.0  4140.0  4150.0  3982.401123   83014700.0\n",
       "244  2023-06-12  4040.0  4050.0  4010.0  4050.0  4050.000000   94687300.0\n",
       "245  2023-06-13  4040.0  4060.0  4030.0  4030.0  4030.000000   69609000.0\n",
       "246  2023-06-14     NaN     NaN     NaN     NaN          NaN          NaN\n",
       "247  2023-06-15  3990.0  4000.0  3990.0  4000.0  4000.000000   12540000.0\n",
       "\n",
       "[248 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('TLKM.JK.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>4060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-16</td>\n",
       "      <td>4040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>4120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>4040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>4110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2023-06-09</td>\n",
       "      <td>4150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>4050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>4030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2023-06-14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   Close\n",
       "0    2022-06-15  4060.0\n",
       "1    2022-06-16  4040.0\n",
       "2    2022-06-17  4120.0\n",
       "3    2022-06-20  4040.0\n",
       "4    2022-06-21  4110.0\n",
       "..          ...     ...\n",
       "243  2023-06-09  4150.0\n",
       "244  2023-06-12  4050.0\n",
       "245  2023-06-13  4030.0\n",
       "246  2023-06-14     NaN\n",
       "247  2023-06-15  4000.0\n",
       "\n",
       "[248 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Date','Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         1\n",
       "High         1\n",
       "Low          1\n",
       "Close        1\n",
       "Adj Close    1\n",
       "Volume       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4060.0\n",
       "1      4040.0\n",
       "2      4120.0\n",
       "3      4040.0\n",
       "4      4110.0\n",
       "        ...  \n",
       "242    4170.0\n",
       "243    4150.0\n",
       "244    4050.0\n",
       "245    4030.0\n",
       "247    4000.0\n",
       "Name: Close, Length: 247, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df['Close']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>4010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>4050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>4050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>4120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Close\n",
       "0    4060.0\n",
       "1    4040.0\n",
       "2    4120.0\n",
       "3    4040.0\n",
       "4    4110.0\n",
       "..      ...\n",
       "193  4010.0\n",
       "194  4050.0\n",
       "195  4050.0\n",
       "196  3990.0\n",
       "197  4120.0\n",
       "\n",
       "[198 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(data)\n",
    "sizeTrain = (round(n*0.8))\n",
    "data_train = pd.DataFrame(data[:sizeTrain])\n",
    "data_test = pd.DataFrame(data[sizeTrain:])\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.408696\n",
       "1     0.391304\n",
       "2     0.391304\n",
       "3     0.434783\n",
       "4     0.426087\n",
       "5     0.400000\n",
       "6     0.417391\n",
       "7     0.400000\n",
       "8     0.478261\n",
       "9     0.565217\n",
       "10    0.608696\n",
       "11    0.608696\n",
       "12    0.617391\n",
       "13    0.643478\n",
       "14    0.643478\n",
       "15    0.582609\n",
       "16    0.582609\n",
       "17    0.695652\n",
       "18    0.626087\n",
       "19    0.565217\n",
       "20    0.513043\n",
       "21    0.478261\n",
       "22    0.478261\n",
       "23    0.495652\n",
       "24    0.400000\n",
       "25    0.408696\n",
       "26    0.460870\n",
       "27    0.426087\n",
       "28    0.330435\n",
       "29    0.330435\n",
       "30    0.330435\n",
       "31    0.339130\n",
       "32    0.365217\n",
       "33    0.382609\n",
       "34    0.382609\n",
       "35    0.486957\n",
       "36    0.452174\n",
       "37    0.460870\n",
       "38    0.521739\n",
       "39    0.452174\n",
       "40    0.382609\n",
       "41    0.417391\n",
       "42    0.426087\n",
       "43    0.478261\n",
       "44    0.495652\n",
       "45    0.478261\n",
       "46    0.391304\n",
       "47    0.373913\n",
       "48    0.347826\n",
       "Name: data, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(data_train)\n",
    "\n",
    "# Mengaplikasikan MinMaxScaler pada data pengujian\n",
    "test_scaled = scaler.transform(data_test)\n",
    "\n",
    "# reshaped_data = data.reshape(-1, 1)\n",
    "train = pd.DataFrame(train_scaled, columns = ['data'])\n",
    "train = train['data']\n",
    "\n",
    "test = pd.DataFrame(test_scaled, columns = ['data'])\n",
    "test = test['data']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "def split_sequence(sequence, n_steps):\n",
    "  X, y = list(), list()\n",
    "  for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "    end_ix = i + n_steps\n",
    "    # check if we are beyond the sequence\n",
    "    if end_ix > len(sequence)-1:\n",
    "      break\n",
    "    # gather input and output parts of the pattern\n",
    "    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "  \n",
    "  return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X, df_Y = split_sequence(train, 3)\n",
    "# for i in range(len(df_X)):\n",
    "#   print(df_X[i], df_Y[i])\n",
    "x = pd.DataFrame(df_X, columns = ['xt-3','xt-2','xt-1'])\n",
    "y = pd.DataFrame(df_Y, columns = ['xt'])\n",
    "dataset_train = pd.concat([x, y], axis=1)\n",
    "dataset_train\n",
    "dataset_train.to_excel('data_train(perhari).xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.3826087 , 0.45217391],\n",
       "       [0.3826087 , 0.45217391, 0.3826087 ],\n",
       "       [0.45217391, 0.3826087 , 0.44347826],\n",
       "       [0.3826087 , 0.44347826, 0.39130435],\n",
       "       [0.44347826, 0.39130435, 0.48695652],\n",
       "       [0.39130435, 0.48695652, 0.47826087],\n",
       "       [0.48695652, 0.47826087, 0.40869565],\n",
       "       [0.47826087, 0.40869565, 0.37391304],\n",
       "       [0.40869565, 0.37391304, 0.3826087 ],\n",
       "       [0.37391304, 0.3826087 , 0.34782609],\n",
       "       [0.3826087 , 0.34782609, 0.36521739],\n",
       "       [0.34782609, 0.36521739, 0.33913043],\n",
       "       [0.36521739, 0.33913043, 0.33913043],\n",
       "       [0.33913043, 0.33913043, 0.36521739],\n",
       "       [0.33913043, 0.36521739, 0.3826087 ],\n",
       "       [0.36521739, 0.3826087 , 0.35652174],\n",
       "       [0.3826087 , 0.35652174, 0.3826087 ],\n",
       "       [0.35652174, 0.3826087 , 0.35652174],\n",
       "       [0.3826087 , 0.35652174, 0.29565217],\n",
       "       [0.35652174, 0.29565217, 0.36521739],\n",
       "       [0.29565217, 0.36521739, 0.47826087],\n",
       "       [0.36521739, 0.47826087, 0.51304348],\n",
       "       [0.47826087, 0.51304348, 0.48695652],\n",
       "       [0.51304348, 0.48695652, 0.53043478],\n",
       "       [0.48695652, 0.53043478, 0.57391304],\n",
       "       [0.53043478, 0.57391304, 0.54782609],\n",
       "       [0.57391304, 0.54782609, 0.55652174],\n",
       "       [0.54782609, 0.55652174, 0.56521739],\n",
       "       [0.55652174, 0.56521739, 0.60869565],\n",
       "       [0.56521739, 0.60869565, 0.55652174],\n",
       "       [0.60869565, 0.55652174, 0.54782609],\n",
       "       [0.55652174, 0.54782609, 0.60869565],\n",
       "       [0.54782609, 0.60869565, 0.73913043],\n",
       "       [0.60869565, 0.73913043, 0.7826087 ],\n",
       "       [0.73913043, 0.7826087 , 0.82608696],\n",
       "       [0.7826087 , 0.82608696, 0.91304348],\n",
       "       [0.82608696, 0.91304348, 0.95652174],\n",
       "       [0.91304348, 0.95652174, 0.90434783],\n",
       "       [0.95652174, 0.90434783, 0.83478261],\n",
       "       [0.90434783, 0.83478261, 0.84347826],\n",
       "       [0.83478261, 0.84347826, 0.82608696],\n",
       "       [0.84347826, 0.82608696, 0.73913043],\n",
       "       [0.82608696, 0.73913043, 0.70434783],\n",
       "       [0.73913043, 0.70434783, 0.82608696],\n",
       "       [0.70434783, 0.82608696, 0.86956522],\n",
       "       [0.82608696, 0.86956522, 0.91304348],\n",
       "       [0.86956522, 0.91304348, 0.92173913],\n",
       "       [0.91304348, 0.92173913, 1.        ],\n",
       "       [0.92173913, 1.        , 0.84347826],\n",
       "       [1.        , 0.84347826, 0.77391304],\n",
       "       [0.84347826, 0.77391304, 0.8       ],\n",
       "       [0.77391304, 0.8       , 0.76521739],\n",
       "       [0.8       , 0.76521739, 0.83478261],\n",
       "       [0.76521739, 0.83478261, 0.85217391],\n",
       "       [0.83478261, 0.85217391, 0.86956522],\n",
       "       [0.85217391, 0.86956522, 0.88695652],\n",
       "       [0.86956522, 0.88695652, 0.79130435],\n",
       "       [0.88695652, 0.79130435, 0.77391304],\n",
       "       [0.79130435, 0.77391304, 0.83478261],\n",
       "       [0.77391304, 0.83478261, 0.86956522],\n",
       "       [0.83478261, 0.86956522, 0.8173913 ],\n",
       "       [0.86956522, 0.8173913 , 0.8       ],\n",
       "       [0.8173913 , 0.8       , 0.76521739],\n",
       "       [0.8       , 0.76521739, 0.7826087 ],\n",
       "       [0.76521739, 0.7826087 , 0.70434783],\n",
       "       [0.7826087 , 0.70434783, 0.7826087 ],\n",
       "       [0.70434783, 0.7826087 , 0.76521739],\n",
       "       [0.7826087 , 0.76521739, 0.72173913],\n",
       "       [0.76521739, 0.72173913, 0.72173913],\n",
       "       [0.72173913, 0.72173913, 0.67826087],\n",
       "       [0.72173913, 0.67826087, 0.74782609],\n",
       "       [0.67826087, 0.74782609, 0.73043478],\n",
       "       [0.74782609, 0.73043478, 0.75652174],\n",
       "       [0.73043478, 0.75652174, 0.73043478],\n",
       "       [0.75652174, 0.73043478, 0.74782609],\n",
       "       [0.73043478, 0.74782609, 0.74782609],\n",
       "       [0.74782609, 0.74782609, 0.73043478],\n",
       "       [0.74782609, 0.73043478, 0.74782609],\n",
       "       [0.73043478, 0.74782609, 0.72173913],\n",
       "       [0.74782609, 0.72173913, 0.65217391],\n",
       "       [0.72173913, 0.65217391, 0.71304348],\n",
       "       [0.65217391, 0.71304348, 0.6173913 ],\n",
       "       [0.71304348, 0.6173913 , 0.64347826],\n",
       "       [0.6173913 , 0.64347826, 0.60869565],\n",
       "       [0.64347826, 0.60869565, 0.6       ],\n",
       "       [0.60869565, 0.6       , 0.63478261],\n",
       "       [0.6       , 0.63478261, 0.56521739],\n",
       "       [0.63478261, 0.56521739, 0.52173913],\n",
       "       [0.56521739, 0.52173913, 0.65217391],\n",
       "       [0.52173913, 0.65217391, 0.66086957],\n",
       "       [0.65217391, 0.66086957, 0.70434783],\n",
       "       [0.66086957, 0.70434783, 0.68695652],\n",
       "       [0.70434783, 0.68695652, 0.66956522],\n",
       "       [0.68695652, 0.66956522, 0.66956522],\n",
       "       [0.66956522, 0.66956522, 0.73913043],\n",
       "       [0.66956522, 0.73913043, 0.68695652],\n",
       "       [0.73913043, 0.68695652, 0.71304348],\n",
       "       [0.68695652, 0.71304348, 0.53913043],\n",
       "       [0.71304348, 0.53913043, 0.46086957],\n",
       "       [0.53913043, 0.46086957, 0.53043478],\n",
       "       [0.46086957, 0.53043478, 0.59130435],\n",
       "       [0.53043478, 0.59130435, 0.53913043],\n",
       "       [0.59130435, 0.53913043, 0.51304348],\n",
       "       [0.53913043, 0.51304348, 0.49565217],\n",
       "       [0.51304348, 0.49565217, 0.47826087],\n",
       "       [0.49565217, 0.47826087, 0.39130435],\n",
       "       [0.47826087, 0.39130435, 0.39130435],\n",
       "       [0.39130435, 0.39130435, 0.39130435],\n",
       "       [0.39130435, 0.39130435, 0.3826087 ],\n",
       "       [0.39130435, 0.3826087 , 0.35652174],\n",
       "       [0.3826087 , 0.35652174, 0.37391304],\n",
       "       [0.35652174, 0.37391304, 0.34782609],\n",
       "       [0.37391304, 0.34782609, 0.32173913],\n",
       "       [0.34782609, 0.32173913, 0.37391304],\n",
       "       [0.32173913, 0.37391304, 0.37391304],\n",
       "       [0.37391304, 0.37391304, 0.33043478],\n",
       "       [0.37391304, 0.33043478, 0.33043478],\n",
       "       [0.33043478, 0.33043478, 0.3826087 ],\n",
       "       [0.33043478, 0.3826087 , 0.31304348],\n",
       "       [0.3826087 , 0.31304348, 0.34782609],\n",
       "       [0.31304348, 0.34782609, 0.20869565],\n",
       "       [0.34782609, 0.20869565, 0.        ],\n",
       "       [0.20869565, 0.        , 0.06956522],\n",
       "       [0.        , 0.06956522, 0.12173913],\n",
       "       [0.06956522, 0.12173913, 0.04347826],\n",
       "       [0.12173913, 0.04347826, 0.08695652],\n",
       "       [0.04347826, 0.08695652, 0.13043478],\n",
       "       [0.08695652, 0.13043478, 0.13043478],\n",
       "       [0.13043478, 0.13043478, 0.06086957],\n",
       "       [0.13043478, 0.06086957, 0.06956522],\n",
       "       [0.06086957, 0.06956522, 0.10434783],\n",
       "       [0.06956522, 0.10434783, 0.10434783],\n",
       "       [0.10434783, 0.10434783, 0.16521739],\n",
       "       [0.10434783, 0.16521739, 0.13043478],\n",
       "       [0.16521739, 0.13043478, 0.15652174],\n",
       "       [0.13043478, 0.15652174, 0.13043478],\n",
       "       [0.15652174, 0.13043478, 0.1826087 ],\n",
       "       [0.13043478, 0.1826087 , 0.11304348],\n",
       "       [0.1826087 , 0.11304348, 0.15652174],\n",
       "       [0.11304348, 0.15652174, 0.13043478],\n",
       "       [0.15652174, 0.13043478, 0.17391304],\n",
       "       [0.13043478, 0.17391304, 0.22608696],\n",
       "       [0.17391304, 0.22608696, 0.19130435],\n",
       "       [0.22608696, 0.19130435, 0.14782609],\n",
       "       [0.19130435, 0.14782609, 0.09565217],\n",
       "       [0.14782609, 0.09565217, 0.16521739],\n",
       "       [0.09565217, 0.16521739, 0.2       ],\n",
       "       [0.16521739, 0.2       , 0.23478261],\n",
       "       [0.2       , 0.23478261, 0.22608696],\n",
       "       [0.23478261, 0.22608696, 0.15652174],\n",
       "       [0.22608696, 0.15652174, 0.2173913 ],\n",
       "       [0.15652174, 0.2173913 , 0.30434783],\n",
       "       [0.2173913 , 0.30434783, 0.28695652],\n",
       "       [0.30434783, 0.28695652, 0.25217391],\n",
       "       [0.28695652, 0.25217391, 0.23478261],\n",
       "       [0.25217391, 0.23478261, 0.2173913 ],\n",
       "       [0.23478261, 0.2173913 , 0.20869565],\n",
       "       [0.2173913 , 0.20869565, 0.32173913],\n",
       "       [0.20869565, 0.32173913, 0.31304348],\n",
       "       [0.32173913, 0.31304348, 0.31304348],\n",
       "       [0.31304348, 0.31304348, 0.2173913 ],\n",
       "       [0.31304348, 0.2173913 , 0.23478261],\n",
       "       [0.2173913 , 0.23478261, 0.25217391],\n",
       "       [0.23478261, 0.25217391, 0.24347826],\n",
       "       [0.25217391, 0.24347826, 0.24347826],\n",
       "       [0.24347826, 0.24347826, 0.17391304],\n",
       "       [0.24347826, 0.17391304, 0.20869565],\n",
       "       [0.17391304, 0.20869565, 0.14782609],\n",
       "       [0.20869565, 0.14782609, 0.17391304],\n",
       "       [0.14782609, 0.17391304, 0.16521739],\n",
       "       [0.17391304, 0.16521739, 0.17391304],\n",
       "       [0.16521739, 0.17391304, 0.16521739],\n",
       "       [0.17391304, 0.16521739, 0.14782609],\n",
       "       [0.16521739, 0.14782609, 0.13913043],\n",
       "       [0.14782609, 0.13913043, 0.19130435],\n",
       "       [0.13913043, 0.19130435, 0.20869565],\n",
       "       [0.19130435, 0.20869565, 0.22608696],\n",
       "       [0.20869565, 0.22608696, 0.32173913],\n",
       "       [0.22608696, 0.32173913, 0.3826087 ],\n",
       "       [0.32173913, 0.3826087 , 0.31304348],\n",
       "       [0.3826087 , 0.31304348, 0.24347826],\n",
       "       [0.31304348, 0.24347826, 0.28695652],\n",
       "       [0.24347826, 0.28695652, 0.24347826],\n",
       "       [0.28695652, 0.24347826, 0.26086957],\n",
       "       [0.24347826, 0.26086957, 0.24347826],\n",
       "       [0.26086957, 0.24347826, 0.24347826],\n",
       "       [0.24347826, 0.24347826, 0.29565217],\n",
       "       [0.24347826, 0.29565217, 0.32173913],\n",
       "       [0.29565217, 0.32173913, 0.35652174],\n",
       "       [0.32173913, 0.35652174, 0.40869565],\n",
       "       [0.35652174, 0.40869565, 0.36521739],\n",
       "       [0.40869565, 0.36521739, 0.35652174],\n",
       "       [0.36521739, 0.35652174, 0.39130435],\n",
       "       [0.35652174, 0.39130435, 0.39130435],\n",
       "       [0.39130435, 0.39130435, 0.33913043]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = dataset_train.iloc[:, :3].values\n",
    "Y_train = dataset_train.iloc[:, -1].values\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = split_sequence(test, 3)\n",
    "# for i in range(len(test_x)):\n",
    "#   print(test_x[i], test_y[i])\n",
    "x = pd.DataFrame(test_x, columns = ['xt-3','xt-2','xt-1'])\n",
    "y = pd.DataFrame(test_y, columns = ['xt'])\n",
    "dataset_test = pd.concat([x, y], axis=1)\n",
    "dataset_test\n",
    "dataset_test.to_excel('data_test(perhari).xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "X_test = dataset_test.iloc[:, :3].values\n",
    "Y_test = dataset_test.iloc[:, -1].values\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = KNeighborsRegressor(n_neighbors=5)\n",
    "model1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "reshaped_data = y_pred.reshape(-1, 1)\n",
    "original_data = scaler.inverse_transform(reshaped_data)\n",
    "reshaped_datates = Y_test.reshape(-1, 1)\n",
    "actual_test = scaler.inverse_transform(reshaped_datates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013784572137377035\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(original_data, actual_test)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnormalisasi MAPE:  [3615.85225796]\n"
     ]
    }
   ],
   "source": [
    "unnormalized_mape = mape * (scaler.data_max_ - scaler.data_min_) + scaler.data_min_\n",
    "\n",
    "print('Unnormalisasi MAPE: ', unnormalized_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LinearRegression()\n",
    "model2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict(X_test)\n",
    "reshaped_data = y_pred2.reshape(-1, 1)\n",
    "original_data = scaler.inverse_transform(reshaped_data)\n",
    "reshaped_datates = Y_test.reshape(-1, 1)\n",
    "actual_test = scaler.inverse_transform(reshaped_datates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013784572137377035\n"
     ]
    }
   ],
   "source": [
    "mape2 = mean_absolute_percentage_error(original_data, actual_test)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnormalisasi MAPE:  [3611.97823393]\n"
     ]
    }
   ],
   "source": [
    "unnormalized_mape2 = mape2 * (scaler.data_max_ - scaler.data_min_) + scaler.data_min_\n",
    "\n",
    "print('Unnormalisasi MAPE: ', unnormalized_mape2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
